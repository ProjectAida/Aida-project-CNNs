{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from datagen_image import run_train, run_eval, run_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type the file path to the file lists for training and validation\n",
    "\n",
    "File Format Instruction:\n",
    "\n",
    "1. Each row in the file represents one entry.\n",
    "\n",
    "2. Every row is divided into two parts, separated by a comma.\n",
    "\n",
    "3. The first part of each row specifies the path of the snippet image. For example: 'sn82003383_1840-04-25_ed-1_seq-1_1_5.jpg'.\n",
    "\n",
    "4. The second part of each row contains the label of the snippet image. The label should be:\n",
    "   - '1' if the snippet image contains poems.\n",
    "   - '0' if the snippet image does not contain poems.\n",
    "\n",
    "Example of a row in the file: 'sn82003383_1840-04-25_ed-1_seq-1_1_5.jpg,1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_list = 'aida17k/train_dataset_aida17k.csv'\n",
    "val_file_list = 'aida17k/valid_dataset_aida17k.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type the path to the parent folder where snippet image files are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'aida17k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a model from:\n",
    "- LeNet-7 (le7)\n",
    "- LeNet-9 (le9)\n",
    "- ResNet-18 (res18)\n",
    "- ResNet-152 (res152)\n",
    "- MobileNetV2 (mnetv2)\n",
    "- EfficientNetB0 (efficientb0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_name = 'le9'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script attempts to fine tune the selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nClass = 2\n",
    "nEpoch = 100\n",
    "model_path = 'pretrained_model/' + mod_name + '_aida17k_192_128_weights_finetune.h5'\n",
    "\n",
    "train_datalist = []\n",
    "with open(os.path.join(train_file_list), 'r') as f:\n",
    "    for lines in f:\n",
    "        train_datalist.append(lines.strip())\n",
    "\n",
    "val_datalist = []\n",
    "with open(os.path.join(val_file_list), 'r') as f:\n",
    "    for lines in f:\n",
    "        val_datalist.append(lines.strip())\n",
    "\n",
    "train_history, model = run_train(train_datalist, \n",
    "                                 val_datalist, \n",
    "                                 base_path, \n",
    "                                 nClass, \n",
    "                                 mod_name, \n",
    "                                 nEpoch)\n",
    "\n",
    "\n",
    "model.save_weights(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
